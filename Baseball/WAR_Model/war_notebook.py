# -*- coding: utf-8 -*-
"""WAR_notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GpuOom0D6YbdvsGFz0U_VHRPnXNiNCQu

# Install
"""

pip install pybaseball

"""# Imports"""

import os
import pandas as pd
import numpy as np
import pybaseball as pyb
from pybaseball import batting_stats

"""# Pull Data and Save Data"""

START = 2002
END = 2022

batting = batting_stats(START, END, qual=200)

batting.to_csv('batting.csv')

# we want players with at least two seasons -- remove groups with one season of data
# IDfg is unique player ID
batting = batting.groupby("IDfg", group_keys=False).filter(lambda x: x.shape[0] > 1)

batting

"""# Prep the target variable"""

# set up target variable - WAR for next season
def next_season(player):
  """take data for single player and backfill WAR value for next season"""
  player = player.sort_values("Season")
  player["Next_WAR"] = player["WAR"].shift(-1)
  return player

# split dataframe by playerId and compute next season WAR for each player
batting = batting.groupby("IDfg", group_keys=False).apply(next_season)

batting[["Name","Season","WAR","Next_WAR"]]

"""# Clean the data"""

# we can also impute these values
# we are counting missing values in each column
null_count = batting.isnull().sum()
null_count

complete_cols = list(batting.columns[null_count==0])
complete_cols

# avoid copy warnings later
batting = batting[complete_cols + ["Next_WAR"]].copy()

batting.dtypes

# handle string values
batting.dtypes[batting.dtypes == "object"]

# for now delete these columns -- could use age in the future
del batting['Dol']
del batting['Age Rng']
batting['team_code'] = batting['Team'].astype("category").cat.codes # ordinal encoding ... careful here

batting_full = batting.copy()
batting = batting.dropna().copy() # drop where next war is null

"""# Model"""

# run feature selector to help model optimize accuracy
# define model (ridge regression model)

from sklearn.linear_model import Ridge
from sklearn.feature_selection import SequentialFeatureSelector
from sklearn.model_selection import TimeSeriesSplit # used in feature selector

# play around with lambda / alpha parameter, the higher it is the more it penalizes Ridge Coeff and avoids overfitting
rr = Ridge(alpha=1)
split = TimeSeriesSplit(n_splits=3) # make predictions for three parts because we have time series data
# go through all the features, find the best one, so on -- direction forward, remove features for direction = backward
sfs = SequentialFeatureSelector(rr, n_features_to_select=20, direction="forward", cv=split, n_jobs=4)

removed_cols = ['Next_WAR', 'Name', 'Team','IDfg', 'Season']
selected_cols = batting.columns[~batting.columns.isin(removed_cols)]

# with ridge regression we have to scale data so mean is 1 and regreesion is 1
from sklearn.preprocessing import MinMaxScaler # puts all vallus betweeen 0-1
scaler = MinMaxScaler()
batting.loc[:, selected_cols] = scaler.fit_transform(batting[selected_cols])

batting.describe()
# columns now have been scaled between 0 and 1

# fit selector to data -- fits best 20 features to give us best results for ridge regression
# then extract list of predictors from feature selector
sfs.fit(batting[selected_cols], batting["Next_WAR"])

predictors = list(selected_cols[sfs.get_support()])
# trues are columns we want to select

def backtest(data, model,predictors, start=5, step=1):
  """what we use to validate data in cross validation -- in timeseries
  we don't want to use data from a future season to predict past season.
  we only want past data to predict future data for timeseries cross validation
  ie. use 2002 to predict 2003, then use 2002, 2003 to predict 2004, etc.
  """

  all_predictions = []
  # get sorted years / seasons
  years = sorted(data["Season"].unique())

  for i in range(start, len(years), step):
    current_year = years[i]
    # split data
    train = data[data["Season"] < current_year]
    test = data[data["Season"] == current_year]
    # define label and data
    x_train = train[predictors]
    x_test = test[predictors]
    y_train = train["Next_WAR"]
    y_test = test["Next_WAR"]
    # fit and predict
    model.fit(x_train, y_train)
    preds = model.predict(x_test)
    # convert to series so easier to work with (column of data)
    preds = pd.Series(preds, index=y_test.index)
    # combine prediction with actuals
    combined = pd.concat([y_test, preds], axis=1)
    # assign column names
    combined.columns = ["actual", "prediction"]
    # append to all predictions - list of dataframes each is a predictions for a different season
    all_predictions.append(combined)
    # concat on axis=0 (vertically one long dataframe)
  return pd.concat(all_predictions)

predictions = backtest(batting, rr, predictors)
predictions

"""# Evaluate"""

# use summary stats to evaluate performance
from sklearn.metrics import mean_squared_error
mean_squared_error(predictions["actual"], predictions["prediction"])

batting["Next_WAR"].describe()

"""We probably want MSE to be lower than the standard dev ideally (typical rule of thumb) -- indicates our model is doing better than randomly guessing."""

2.736105953760221 ** 0.5
# take away square root and we see the value is slightly lower which tells us our model is ok.

"""# Improving Accuracy

Right now we are only telling the model what happened in the current season, we might want to tell the model what happened in past seasons -- might be useful to see if the player is in decline
"""

# example:
ga = batting[batting["IDfg"] == 2]
ga["player_season"] = range(0,ga.shape[0])
# defines groups and finds correlation within each group that expanding creates
# two index value to select one number
ga[["player_season", "WAR"]].expanding().corr().loc[(slice(None), "player_season"),"WAR"]

def group_averages(df):
  """did our player play better than an average player"""
  return df["WAR"] / df["WAR"].mean()

def player_history(df):
  df = df.sort_values("Season")
  # indicates which season it is for the player
  df["player_season"] = range(0,df.shape[0])
  df["war_corr"] = list(df[["player_season", "WAR"]].expanding().corr().loc[(slice(None), "player_season"), "WAR"])
  # 1 implies 1:1 correlation
  df["war_corr"].fillna(1, inplace=True)
  # brings prevous season up to current
  df["war_diff"] = df["WAR"] / df["WAR"].shift(1)
  df["war_diff"].fillna(1,inplace=True)
  df["war_diff"][df["war_diff"] == np.inf] = 1
  return df

batting = batting.groupby("IDfg", group_keys = False).apply(player_history)

# how average player performed
batting["war_season"] = batting.groupby("Season", group_keys=False).apply(group_averages)

new_predictors = predictors + ["player_season","war_corr", "war_season", "war_diff"]

predictons = backtest(batting, rr, new_predictors)
mean_squared_error(predictions["actual"], predictions["prediction"])

"""# Evaluate Predictors"""

pd.Series(rr.coef_, index=new_predictors).sort_values()
# use this to diagnose which predictors are best

diff = predictions["actual"] - predictions["prediction"]

merged = predictions.merge(batting,left_index=True, right_index=True)
merged["diff"] = predictions["actual"] - predictions["prediction"].abs()
# merged[['IDfg', "Season",'Name', 'WAR', 'Next_WAR']]]

"""# Next steps

- Use better data (ie. minor league data, etc.)
- Use a different model
- Use different selection strategies
- Feature engineering
"""

